{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tournament test of the 13 iterations of the network\n",
    "\n",
    "The following code loads the 13 iterations of the network and plays 2 games between all combinations of the iterations of the network such that each network gets to start once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Nov 15 14:57:23 2018\n",
    "\n",
    "@author: jevcl\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "from torch.nn.parameter import Parameter\n",
    "import pickle\n",
    "\n",
    "from torch.nn import Linear, Conv2d, BatchNorm2d, MaxPool2d, Dropout2d\n",
    "from torch.nn.functional import relu, elu, relu6, sigmoid, tanh, softmax\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#====================================================================================\n",
    "#Othello\n",
    "#====================================================================================\n",
    "\n",
    "class GameState:\n",
    "    \n",
    "    #define adjacent cells\n",
    "    adjacentCells = [[1,0],[1,1],[0,1],[-1,1],[-1,0],[-1,-1],[0,-1],[1,-1]]\n",
    "    height = 8\n",
    "    width = 8\n",
    "\n",
    "    #define enemy of player\n",
    "    def enemy(self):\n",
    "        if(self.player == 1):\n",
    "            return 2\n",
    "        elif(self.player == 2):\n",
    "            return 1\n",
    "\n",
    "    #out of bounds function\n",
    "    def oob(x,y):\n",
    "        if x > GameState.height-1 or y > GameState.width-1 or x < 0 or y < 0:\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def moveToIndex(move):\n",
    "        if move == (-1,-1):\n",
    "            return GameState.height*GameState.width\n",
    "        return move[0]*GameState.height+move[1]\n",
    "    \n",
    "    #initialize new game state, can be a copy of existing game state\n",
    "    def __init__(self, original=None):\n",
    "        if original != None:\n",
    "            self.board = np.copy(original.board)\n",
    "            self.player = np.copy(original.player)\n",
    "    \n",
    "    #Creates Board. Empty slot = 0. Black = 1. White = 2.\n",
    "    def makeInitialState(self):\n",
    "        board = np.zeros((GameState.height,GameState.width))\n",
    "        board[int(GameState.height/2-1)][int(GameState.width/2-1)] = 2\n",
    "        board[int(GameState.height/2)][int(GameState.width/2)] = 2\n",
    "        board[int(GameState.height/2-1)][int(GameState.width/2)] = 1\n",
    "        board[int(GameState.height/2)][int(GameState.width/2-1)] = 1\n",
    "        self.board = board\n",
    "        self.player = 1\n",
    "        \n",
    "    def makeTestState(self):\n",
    "        board = np.zeros((GameState.height,GameState.width))\n",
    "        board[0][0] = 1\n",
    "        board[1][1] = 1\n",
    "        board[1][2] = 1\n",
    "        board[2][1] = 2\n",
    "        board[2][2] = 1\n",
    "        board[3][1] = 2\n",
    "        board[3][2] = 2\n",
    "        board[3][3] = 2\n",
    "        self.board = board\n",
    "        self.player = 1\n",
    "        \n",
    "    def toVector(self, cuda = False):\n",
    "        player = -1 if self.player == 1 else 1\n",
    "        ret = self.board.flatten()\n",
    "        ret = np.append(ret, player)\n",
    "        ret = torch.from_numpy(ret).float()\n",
    "        if cuda:\n",
    "            ret = ret.cuda()\n",
    "        return ret\n",
    "\n",
    "    def toNetState(self, cuda = False):\n",
    "        ret = torch.zeros(1,2,GameState.height,GameState.width)\n",
    "        enemy = self.enemy()\n",
    "        for i in range(GameState.height):\n",
    "            for j in range(GameState.width):\n",
    "                if self.board[i,j] == self.player:\n",
    "                    ret[0,0,i,j] = 1\n",
    "                elif self.board[i,j] == enemy:\n",
    "                    ret[0,1,i,j] = 1\n",
    "        if cuda:\n",
    "            ret = ret.cuda()\n",
    "        return ret\n",
    "\n",
    "    #Update all cells after move. Observe, this function does not care wether the move is legal or not.\n",
    "    def updateState(self, move):\n",
    "        newGameState = GameState(self)\n",
    "        if move != (-1,-1):\n",
    "            xCord, yCord = move\n",
    "            for xVec,yVec in GameState.adjacentCells:\n",
    "                newGameState.updateDirection(xCord, yCord, xVec, yVec)\n",
    "        newGameState.player = newGameState.enemy()\n",
    "        return newGameState\n",
    "\n",
    "    #Update cells in one direction\n",
    "    def updateDirection(self, xCord, yCord, xVec, yVec):\n",
    "        x = xCord + xVec\n",
    "        y = yCord + yVec\n",
    "        if GameState.oob(x,y) or self.board[x][y] == 0:\n",
    "            return False\n",
    "        elif self.board[x][y] == self.player:\n",
    "            self.board[xCord][yCord] = self.player\n",
    "            return True\n",
    "        else:\n",
    "            ret = self.updateDirection(x, y, xVec, yVec)\n",
    "            if ret:\n",
    "                self.board[xCord][yCord] = self.player\n",
    "            return ret\n",
    "\n",
    "    #Find all legal moves for player\n",
    "    def findLegalMoves(self, hasCheckedEnemy=False):\n",
    "        legalMoves = [];\n",
    "        for xCord in range(GameState.height):\n",
    "            for yCord in range(GameState.width):\n",
    "                if self.board[xCord][yCord] != 0:\n",
    "                    continue\n",
    "                for xVec,yVec in GameState.adjacentCells:\n",
    "                    if self.testLegalDirection(xCord, yCord, xVec, yVec, False):\n",
    "                        legalMoves.append((xCord,yCord))\n",
    "                        break\n",
    "        if len(legalMoves) == 0 and hasCheckedEnemy == False:\n",
    "            enemyState = self.updateState((-1,-1))\n",
    "            enemyMoves = enemyState.findLegalMoves(True)\n",
    "            if len(enemyMoves) > 0:\n",
    "                legalMoves.append((-1,-1)) #do nothing, give over the turn to the enemy\n",
    "        return legalMoves\n",
    "\n",
    "    #Determine if move is legal based on one direction\n",
    "    def testLegalDirection(self, xCord, yCord, xVec, yVec, enemySquare):\n",
    "        x = xCord + xVec\n",
    "        y = yCord + yVec\n",
    "        if GameState.oob(x,y) or self.board[x][y] == 0:\n",
    "            return False\n",
    "        elif self.board[x][y] == self.enemy():\n",
    "            return self.testLegalDirection(x, y, xVec, yVec, True)\n",
    "        elif self.board[x][y] == self.player and enemySquare:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def gameScore(self):\n",
    "        p, e = self.score()\n",
    "        if p > e:\n",
    "            return 1\n",
    "        elif e > p:\n",
    "            return -1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def gameWinner(self):\n",
    "        p, e = self.score();\n",
    "        if self.player == 1 and p > e or self.player == 2 and e > p:\n",
    "            print(\"Black Wins!\")\n",
    "        elif self.player == 1 and p < e or self.player == 2 and e < p:\n",
    "            print(\"White Wins!\")\n",
    "        else:\n",
    "            print(\"Draw!\")\n",
    "\n",
    "    def score(self):\n",
    "        enemy = self.enemy()\n",
    "        p = 0\n",
    "        e = 0\n",
    "        for xCord in range(GameState.height):\n",
    "            for yCord in range(GameState.width):\n",
    "                if self.board[xCord][yCord] == self.player:\n",
    "                    p += 1\n",
    "                elif self.board[xCord][yCord] == enemy:\n",
    "                    e += 1\n",
    "        return p, e\n",
    "    \n",
    "#====================================================================================\n",
    "#Monte-Carlo\n",
    "#====================================================================================\n",
    "    \n",
    "class MCTS:\n",
    "    \n",
    "    def __init__(self, numberOfSimulations, smartQ = False, network = None, cuda = False):\n",
    "        self.numberOfSimulations = numberOfSimulations\n",
    "        self.smartQ = smartQ\n",
    "        self.network = network\n",
    "        self.cuda= cuda\n",
    "        \n",
    "    def simulate(self, root):\n",
    "        self.root = root\n",
    "        nTotalRoot = int(root.N)\n",
    "        for nTotal in range(nTotalRoot + 1, nTotalRoot + 1 + self.numberOfSimulations):\n",
    "            #print(nTotal)\n",
    "            currentNode = self.root\n",
    "            \n",
    "            while(True):\n",
    "                #print(currentNode.gameState.board)\n",
    "                if currentNode.isLeaf():\n",
    "                    break\n",
    "                else:\n",
    "                    currentNode = currentNode.chooseNodeToExplore(nTotal)\n",
    "            gameResult = currentNode.expand(nTotal)\n",
    "            currentNode.backpropagate(gameResult, currentNode.gameState.player)\n",
    "                \n",
    "    def rootWithActionProbs(self):\n",
    "        totalVisits = sum(c.N for c in self.root.children)\n",
    "        actionProbs = torch.zeros(GameState.height*GameState.width + 2)\n",
    "        for c in self.root.children:\n",
    "            actionProbs[GameState.moveToIndex(c.move)] = c.N/totalVisits\n",
    "        return self.root.gameState.toNetState(), actionProbs\n",
    "        \n",
    "    def bestChildState(self):\n",
    "        bestChild = None\n",
    "        #print(\"looking for move for state: \")\n",
    "        #print(self.root.gameState.board)\n",
    "        visits = []\n",
    "        for child in self.root.children:\n",
    "            visits.append(child.N)\n",
    "            #print(child.numberOfVisits)\n",
    "            #print(child.move)\n",
    "        visits = np.array(visits)\n",
    "        ######print(visits)                         #this is the one        \n",
    "        best = np.argwhere(visits == max(visits))\n",
    "        bestChild = self.root.children[random.choice(best)[0]]\n",
    "        #print(bestChild.move)\n",
    "        return bestChild\n",
    "    \n",
    "    def sampleChildState(self):\n",
    "        totalVisits = sum(c.N for c in self.root.children)\n",
    "        probs = [c.N/totalVisits for c in self.root.children]\n",
    "        child = np.random.choice(self.root.children, 1, p = probs)[0]\n",
    "        return child\n",
    "    \n",
    "class TreeNode:\n",
    "    children = None\n",
    "    parent = None\n",
    "    \n",
    "    def isLeaf(self):\n",
    "        return self.children == None or len(self.children) == 0\n",
    "    \n",
    "class MCTSNode(TreeNode):\n",
    "    \n",
    "    def __init__(self, gameState, prior = 1., move = None, parent = None, network = None, smartQ = False, cuda = False):\n",
    "        self.gameState = gameState\n",
    "        self.move = move\n",
    "        self.W = 0.\n",
    "        self.N = 0.\n",
    "        self.Q = 0.\n",
    "        self.P = prior\n",
    "        self.parent = parent\n",
    "        self.network = network\n",
    "        self.smartQ = smartQ\n",
    "        self.cuda = cuda\n",
    "        \n",
    "    def setToRoot(self):\n",
    "        self.parent = None\n",
    "        \n",
    "    def expand(self, nTotal):\n",
    "        self.children, gameResult = self.computeChildNodes()\n",
    "        if self.isLeaf():\n",
    "            #print(\"leaf hit!!\")\n",
    "            #print(self.gameState.board)\n",
    "            gameResult = self.gameState.gameScore()     \n",
    "        elif self.network == None:\n",
    "            gameResult = self.rollout()\n",
    "        #print(gameResult)\n",
    "        return gameResult\n",
    "    \n",
    "    def chooseNodeToExplore(self, nTotal, cParam = 1.):\n",
    "        choicesWeights = [c.nodeChoiceMetric(nTotal, cParam) for c in self.children]\n",
    "        return self.children[np.argmax(choicesWeights)]\n",
    "        \n",
    "    def computeChildNodes(self):\n",
    "        legalMoves = self.gameState.findLegalMoves()     \n",
    "        if self.network == None:\n",
    "            prior = torch.ones(1,GameState.height*GameState.width+1)\n",
    "            gameResult = None\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                inp = self.gameState.toNetState(self.cuda)\n",
    "                inp = getRandomRotationOrReflection(inp)\n",
    "                net = self.network(inp)\n",
    "            prior = net[0]\n",
    "            gameResult = net[1]\n",
    "            #######\n",
    "            #print(priori)\n",
    "            prior -= 100\n",
    "            for move in legalMoves:\n",
    "                prior[0,GameState.moveToIndex(move)] += 100\n",
    "            prior = softmax(prior, dim=1)\n",
    "            #print(priori)\n",
    "            #priori = torch.ones(1,GameState.height*GameState.width)\n",
    "            #print(priori)\n",
    "            #for move in legalMoves:\n",
    "            #    print(priori[0,GameState.moveToIndex(move)])\n",
    "            #print(gameResult)\n",
    "        childNodes = [MCTSNode(self.gameState.updateState(move), prior[0,GameState.moveToIndex(move)], move, self, self.network, self.smartQ, self.cuda) for move in legalMoves]\n",
    "        #childNodes = [MCTSNode(self.gameState.updateState(move), priori[GameState.moveToIndex(move)], move, self, self.network, self.smartQ, self.cuda) for move in legalMoves]\n",
    "        return childNodes, gameResult\n",
    "    \n",
    "    def nodeChoiceMetric(self, nTotal, cParam):\n",
    "        #if numberOfVisits == 0:\n",
    "        #    return float(\"inf\") #if the node has not been visited before, we should do that asap\n",
    "        #print(self.Q)\n",
    "        #print(cParam * self.priori * math.sqrt((np.log(nTotal) / (1 + numberOfVisits))))\n",
    "        v =  self.Q + cParam * self.P * math.sqrt(nTotal) / (1 + self.N)\n",
    "        return v\n",
    "    \n",
    "    def rollout(self):\n",
    "        currentRolloutState = self.gameState\n",
    "        while(True):\n",
    "            possibleMoves = currentRolloutState.findLegalMoves()\n",
    "            if len(possibleMoves) > 0:\n",
    "                move = self.rolloutPolicy(possibleMoves)\n",
    "                currentRolloutState = currentRolloutState.updateState(move)\n",
    "            else:\n",
    "                break\n",
    "        rolloutResult = currentRolloutState.gameScore()\n",
    "        return rolloutResult\n",
    "            \n",
    "    \n",
    "    def backpropagate(self, gameResult, leafPlayer):\n",
    "        if self.gameState.player == leafPlayer:\n",
    "            direction = -1\n",
    "        else:\n",
    "            direction = 1\n",
    "        self.N += 1.\n",
    "        self.W += direction*gameResult\n",
    "        self.Q = self.W / self.N\n",
    "        if self.parent != None:\n",
    "            self.parent.backpropagate(gameResult, leafPlayer)\n",
    "    \n",
    "    def rolloutPolicy(self, possibleMoves):\n",
    "        return possibleMoves[np.random.randint(len(possibleMoves))]\n",
    "    \n",
    "#====================================================================================\n",
    "#Machine Learning\n",
    "#====================================================================================\n",
    "\n",
    "#network specifications\n",
    "learningRate = 0.01    \n",
    "channels = 2\n",
    "numFiltersConv1 = 32\n",
    "kernelSizeConv1 = 3\n",
    "strideConv1 = 1\n",
    "paddingConv1 = 1\n",
    "\n",
    "numFiltersConvVH = 1\n",
    "kernelSizeConvVH = 1\n",
    "strideConvVH = 1\n",
    "inFeaturesLVH = numFiltersConvVH * GameState.height * GameState.width\n",
    "outFeaturesLVH = GameState.height * GameState.width\n",
    "\n",
    "numFiltersConvPH = 2\n",
    "kernelSizeConvPH = 1\n",
    "strideConvPH = 1\n",
    "inFeaturesLPH = numFiltersConvPH * GameState.height * GameState.width\n",
    "outFeaturesLPH = GameState.height * GameState.width + 1\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \"\"\"Policy network\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.c1 = Conv2d(in_channels=channels,\n",
    "                         out_channels=numFiltersConv1,\n",
    "                         kernel_size=kernelSizeConv1,\n",
    "                         stride=strideConv1,\n",
    "                         padding=paddingConv1)\n",
    "        \n",
    "        self.batchNorm1 = nn.BatchNorm2d(numFiltersConv1)\n",
    "        \n",
    "        # Residual layer 1\n",
    "        self.c2 = Conv2d(in_channels=numFiltersConv1,\n",
    "                         out_channels=numFiltersConv1,\n",
    "                         kernel_size=kernelSizeConv1,\n",
    "                         stride=strideConv1,\n",
    "                         padding=paddingConv1)\n",
    "        \n",
    "        self.batchNorm2 = nn.BatchNorm2d(numFiltersConv1)\n",
    "        \n",
    "        self.c3 = Conv2d(in_channels=numFiltersConv1,\n",
    "                         out_channels=numFiltersConv1,\n",
    "                         kernel_size=kernelSizeConv1,\n",
    "                         stride=strideConv1,\n",
    "                         padding=paddingConv1)\n",
    "        \n",
    "        self.batchNorm3 = nn.BatchNorm2d(numFiltersConv1)\n",
    "        \n",
    "        # Residual layer 2\n",
    "        self.c4 = Conv2d(in_channels=numFiltersConv1,\n",
    "                         out_channels=numFiltersConv1,\n",
    "                         kernel_size=kernelSizeConv1,\n",
    "                         stride=strideConv1,\n",
    "                         padding=paddingConv1)\n",
    "        \n",
    "        self.batchNorm4 = nn.BatchNorm2d(numFiltersConv1)\n",
    "        \n",
    "        self.c5 = Conv2d(in_channels=numFiltersConv1,\n",
    "                         out_channels=numFiltersConv1,\n",
    "                         kernel_size=kernelSizeConv1,\n",
    "                         stride=strideConv1,\n",
    "                         padding=paddingConv1)\n",
    "        \n",
    "        self.batchNorm5 = nn.BatchNorm2d(numFiltersConv1)\n",
    "        \n",
    "        # Residual layer 3\n",
    "        self.c6 = Conv2d(in_channels=numFiltersConv1,\n",
    "                         out_channels=numFiltersConv1,\n",
    "                         kernel_size=kernelSizeConv1,\n",
    "                         stride=strideConv1,\n",
    "                         padding=paddingConv1)\n",
    "        \n",
    "        self.batchNorm6 = nn.BatchNorm2d(numFiltersConv1)\n",
    "        \n",
    "        self.c7 = Conv2d(in_channels=numFiltersConv1,\n",
    "                         out_channels=numFiltersConv1,\n",
    "                         kernel_size=kernelSizeConv1,\n",
    "                         stride=strideConv1,\n",
    "                         padding=paddingConv1)\n",
    "        \n",
    "        self.batchNorm7 = nn.BatchNorm2d(numFiltersConv1)\n",
    "        \n",
    "        # Residual layer 4\n",
    "        self.c8 = Conv2d(in_channels=numFiltersConv1,\n",
    "                         out_channels=numFiltersConv1,\n",
    "                         kernel_size=kernelSizeConv1,\n",
    "                         stride=strideConv1,\n",
    "                         padding=paddingConv1)\n",
    "        \n",
    "        self.batchNorm8 = nn.BatchNorm2d(numFiltersConv1)\n",
    "        \n",
    "        self.c9 = Conv2d(in_channels=numFiltersConv1,\n",
    "                         out_channels=numFiltersConv1,\n",
    "                         kernel_size=kernelSizeConv1,\n",
    "                         stride=strideConv1,\n",
    "                         padding=paddingConv1)\n",
    "        \n",
    "        self.batchNorm9 = nn.BatchNorm2d(numFiltersConv1)\n",
    "        \n",
    "        # PH head\n",
    "        self.convPH = Conv2d(in_channels=numFiltersConv1,\n",
    "            out_channels=numFiltersConvPH,\n",
    "            kernel_size=kernelSizeConvPH,\n",
    "            stride=strideConvPH)\n",
    "        \n",
    "        self.batchNormPH = nn.BatchNorm2d(numFiltersConvPH)\n",
    "        \n",
    "        self.lPH = Linear(in_features=inFeaturesLPH,\n",
    "                          out_features=outFeaturesLPH,\n",
    "                          bias=True)\n",
    "        \n",
    "        # VH\n",
    "        self.convVH = Conv2d(in_channels=numFiltersConv1,\n",
    "            out_channels=numFiltersConvVH,\n",
    "            kernel_size=kernelSizeConvVH,\n",
    "            stride=strideConvVH)\n",
    "        \n",
    "        self.batchNormVH = nn.BatchNorm2d(numFiltersConvVH)\n",
    "        \n",
    "        self.lVH = Linear(in_features=inFeaturesLVH,\n",
    "                          out_features=outFeaturesLVH,\n",
    "                          bias=True)\n",
    "        \n",
    "        self.lVHout = Linear(in_features=outFeaturesLVH,\n",
    "                          out_features=1,\n",
    "                          bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.batchNorm1(relu(self.c1(x)))\n",
    "        res1 = x\n",
    "        x = self.batchNorm2(relu(self.c2(x)))\n",
    "        x = self.batchNorm3(relu(self.c3(x)))\n",
    "        x += res1\n",
    "        res2 = x\n",
    "        x = self.batchNorm4(relu(self.c4(x)))\n",
    "        x = self.batchNorm5(relu(self.c5(x)))\n",
    "        x += res2\n",
    "        res3 = x\n",
    "        x = self.batchNorm6(relu(self.c6(x)))\n",
    "        x = self.batchNorm7(relu(self.c7(x)))\n",
    "        x += res3\n",
    "        res4 = x\n",
    "        x = self.batchNorm8(relu(self.c8(x)))\n",
    "        x = self.batchNorm9(relu(self.c9(x)))\n",
    "        x += res4\n",
    "        ph = self.batchNormPH(relu(self.convPH(x)))\n",
    "        ph = ph.view(-1, inFeaturesLPH)\n",
    "        ph = self.lPH(ph)\n",
    "        vh = self.batchNormVH(relu(self.convVH(x)))\n",
    "        vh = vh.view(-1, inFeaturesLVH)\n",
    "        vh = relu(self.lVH(vh))\n",
    "        vh = torch.tanh(self.lVHout(vh))\n",
    "        return ph, vh\n",
    "    \n",
    "    def loss(self, actionProbabilities, returns):\n",
    "        v = actionProbabilities[1]\n",
    "        z = returns[1]\n",
    "        dif = (z-v)\n",
    "        p = actionProbabilities[0]\n",
    "        pi = returns[0]\n",
    "        meanSqrErr = torch.mean(torch.mul(dif,dif))     \n",
    "        cEL = -torch.mean(torch.sum(pi * torch.log(softmax(p, dim=1)), dim=1))\n",
    "        #print(pi)\n",
    "        #print(p)\n",
    "        #print(torch.log(p))\n",
    "        #print(torch.log(1-p))\n",
    "        #print(meanSqrErr)\n",
    "        #print(cEL)\n",
    "        if meanSqrErr != meanSqrErr or cEL != cEL:\n",
    "            raise Exception(\"This should never happen, we might have inf or nan in loss.\")\n",
    "        return meanSqrErr + cEL\n",
    "    \n",
    "def compute_returns(rewards, discount_factor):\n",
    "    \"\"\"Compute discounted returns.\"\"\"\n",
    "    returns = np.zeros(len(rewards))\n",
    "    returns[-1] = rewards[-1]\n",
    "    for t in reversed(range(len(rewards)-1)):\n",
    "        returns[t] = rewards[t] + discount_factor * returns[t+1]\n",
    "    return returns\n",
    "\n",
    "def saveCheckpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')\n",
    "        print(\"=> saving new best network: \", filename) \n",
    "        \n",
    "def loadCheckpoint(network, resume):\n",
    "    if os.path.isfile(resume):\n",
    "        print(\"=> loading checkpoint '{}'\".format(resume))\n",
    "        checkpoint = torch.load(resume)\n",
    "        network.load_state_dict(checkpoint['state_dict'])\n",
    "        print(\"=> loaded checkpoint '{}'\".format(resume))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(resume)) \n",
    "    \n",
    "    if cuda:\n",
    "        print('##converting network to cuda-enabled')\n",
    "    return network\n",
    "        \n",
    "def selfPlay(player):\n",
    "    initialState = GameState()\n",
    "    initialState.makeInitialState()\n",
    "    \n",
    "    state = initialState\n",
    "    #stateNode = MCTSNode(state, 1., None, None, player.network, player.smartQ, player.cuda)\n",
    "    \n",
    "    states = []\n",
    "    rewards = []\n",
    "    \n",
    "    moveNo = 0\n",
    "    \n",
    "    while(len(state.findLegalMoves()) > 0):\n",
    "        stateNode = MCTSNode(state, 1., None, None, player.network, player.smartQ, player.cuda)\n",
    "        player.simulate(stateNode)\n",
    "        sample = player.rootWithActionProbs()\n",
    "        s = sample[0]\n",
    "        #s = getRotationsAndReflections(s)\n",
    "        r = torch.stack([sample[1][:-2].view(GameState.height,GameState.width)])\n",
    "        #r = getRotationsAndReflections(r)\n",
    "        rew = r.view(-1,GameState.height*GameState.width)\n",
    "        rOut = []\n",
    "        for r in reversed(rew):\n",
    "            rOut.append(torch.cat((r,torch.tensor([sample[1][-2]]))))\n",
    "        r = torch.stack(rOut)\n",
    "        \n",
    "        if len(states) == 0:\n",
    "            states = s\n",
    "            rewards = r\n",
    "        else:\n",
    "            states = torch.cat((states,s))\n",
    "            rewards = torch.cat((rewards,r))\n",
    "        if moveNo < 10:\n",
    "            childNode = player.sampleChildState()\n",
    "        else:\n",
    "            childNode = player.bestChildState()\n",
    "        stateNode = childNode\n",
    "        state = stateNode.gameState\n",
    "        moveNo += 1\n",
    "    gs = state.gameScore()\n",
    "    rOut = []\n",
    "    for r in reversed(rewards):\n",
    "        gs*=-1\n",
    "        rOut.insert(0,torch.cat((r,torch.tensor([gs]).float())))\n",
    "    rOut = torch.stack(rOut)\n",
    "    #for i in range(len(states)):\n",
    "    #    print(states[i])\n",
    "    #    print(rOut[i])\n",
    "    return states, rOut\n",
    "\n",
    "def testVsBest(currentNetwork, bestNetwork, noOfGames):\n",
    "    w = 0\n",
    "    l = 0\n",
    "    d = 0\n",
    "    for i in range(noOfGames):        \n",
    "        if i % 2 == 0:\n",
    "            blackPlayer = currentNetwork\n",
    "            whitePlayer = bestNetwork\n",
    "            direction = 1\n",
    "        else:\n",
    "            blackPlayer = bestNetwork\n",
    "            whitePlayer = currentNetwork\n",
    "            direction = -1\n",
    "        \n",
    "        initialState = GameState()\n",
    "        initialState.makeInitialState()\n",
    "        #initialState.makeTestState()\n",
    "        \n",
    "        isBlackplayersTurn = True\n",
    "        player = blackPlayer\n",
    "        \n",
    "        state = initialState\n",
    "\n",
    "        while(len(state.findLegalMoves()) > 0):\n",
    "            stateNode = MCTSNode(state, 1., None, None, player.network, player.smartQ, player.cuda)\n",
    "            player.simulate(stateNode)\n",
    "            state = player.bestChildState().gameState\n",
    "            direction *= -1\n",
    "\n",
    "            #print(state.board)\n",
    "            #print(state.player)\n",
    "            #root, ap = player.rootWithActionProbs()\n",
    "            #print(ap)\n",
    "            #print(currentNetwork.network(root))\n",
    "            #print(bestNetwork.network(root))\n",
    "            #break\n",
    "            if isBlackplayersTurn:\n",
    "                #print(\"white players turn\")\n",
    "                player = whitePlayer\n",
    "                isBlackplayersTurn = False\n",
    "            else:\n",
    "                #print(\"black players turn\")\n",
    "                player = blackPlayer\n",
    "                isBlackplayersTurn = True\n",
    "\n",
    "                \n",
    "        score = state.gameScore()\n",
    "        score *= direction\n",
    "        if score == -1:\n",
    "            l += 1\n",
    "        elif score == 1:\n",
    "            w += 1\n",
    "        else:\n",
    "            d += 1\n",
    "                \n",
    "        #state.gameWinner()\n",
    "    if noOfGames == d:\n",
    "        return 0, w, l, d\n",
    "    return w/(noOfGames-d), w, l, d\n",
    "\n",
    "def shuffle(states, rewards):\n",
    "    r = torch.randperm(len(states))\n",
    "    return states[r], rewards[r]\n",
    "\n",
    "def getSlice(states, rewards, batchSize, i):\n",
    "    return states[range(i*batchSize,(i+1)*batchSize)], rewards[range(i*batchSize,(i+1)*batchSize)]\n",
    "\n",
    "def randomBatch(states, rewards, batchSize):\n",
    "    r = random.sample(range(len(states)), batchSize)\n",
    "    return states [r], rewards[r]\n",
    "\n",
    "def getRotationsAndReflections(t):\n",
    "    ret = t.clone()\n",
    "    ret = torch.cat((t,t.transpose(-2,-1)))\n",
    "    ret = torch.cat((ret,t.flip(-2)))\n",
    "    ret = torch.cat((ret,t.flip(-1)))\n",
    "    ret = torch.cat((ret,t.transpose(-2,-1).flip(-2)))\n",
    "    ret = torch.cat((ret,t.transpose(-2,-1).flip(-1)))\n",
    "    ret = torch.cat((ret,t.flip(-2).flip(-1)))\n",
    "    ret = torch.cat((ret,t.transpose(-2,-1).flip(-2).flip(-1)))\n",
    "    return ret\n",
    "\n",
    "def getRandomRotationOrReflection(t):\n",
    "    rot = getRotationsAndReflections(t)\n",
    "    r = random.randint(0, len(t)-1)\n",
    "    return rot[r:r+1]    \n",
    "\n",
    "player1Net = Net()\n",
    "player2Net  = Net()\n",
    "\n",
    "iterations = 13\n",
    "mctsSims = 1600\n",
    "\n",
    "for i in range(iterations):\n",
    "  for j in range(iterations):  \n",
    "    if i == j:\n",
    "      continue\n",
    "    player1Name = \"checkpoint8by8_\" + str(i) + \".pth\"\n",
    "    player2Name = \"checkpoint8by8_\" + str(j) + \".pth\"\n",
    "    player1Net.load_state_dict(torch.load(player1Name))\n",
    "    player2Net.load_state_dict(torch.load(player2Name))\n",
    "    print(\"Players: \")\n",
    "    print(player1Name)\n",
    "    print(player2Name)\n",
    "    p1 = MCTS(mctsSims, True, player1Net, False)\n",
    "    p2 = MCTS(mctsSims, True, player2Net, False)\n",
    "    wr = testVsBest(p1, p2, 1)\n",
    "    print(wr)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
